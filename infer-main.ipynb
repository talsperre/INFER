{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "\n",
    "from KittiDataset import KittiDataset\n",
    "from Model import EnDeWithPooling, EnDeConvLSTM_ws, SkipLSTMEnDe\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTransformedImages(imageTensor):\n",
    "    to_pil = torchvision.transforms.ToPILImage()\n",
    "    im = to_pil(imageTensor)\n",
    "    mn, mx = np.min(im), np.max(im)\n",
    "    im = (im - mn) / (mx - mn)\n",
    "    print(im)\n",
    "    plt.imshow(im, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrajectory(xValsGT, yValsGT, xValsPred, yValsPred, xValsPredMulti, yValsPredMulti, seqLen, im_path, numFrames=None):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.plot(yValsGT, xValsGT, c='r', label='Ground Truth')\n",
    "    plt.plot(yValsPred, xValsPred, c='g', label='Prediction')\n",
    "    plt.plot(yValsPredMulti, xValsPredMulti, c='b', label='Multimodal Prediction', alpha=0.8)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([1, 512])\n",
    "    axes.set_ylim([1, 512])\n",
    "    plt.xlabel('X-Axis')\n",
    "    plt.ylabel('Y-Axis')\n",
    "    plt.legend(loc='upper right')\n",
    "    if numFrames == None:\n",
    "        plt.title('Trajectory')\n",
    "    else:\n",
    "        plot_title = 'Trajectory (' + str(numFrames // 10 - 2) + \"s)\"\n",
    "        plt.title(plot_title)\n",
    "    plt.savefig(im_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmapAccuracy(outputMap, labelMap, thr=1.5):\n",
    "    pred = np.unravel_index(outputMap.argmax(), outputMap.shape)\n",
    "    gt = np.unravel_index(labelMap.argmax(), labelMap.shape)\n",
    "\n",
    "    dist = math.sqrt((pred[0] - gt[0]) ** 2 + (pred[1] - gt[1]) ** 2)\n",
    "    if dist <= thr:\n",
    "        return 1, dist, (pred[0], pred[1]), (gt[0], gt[1])\n",
    "    return 0, dist, (pred[0], pred[1]), (gt[0], gt[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_indices(ary, n):\n",
    "    \"\"\"Returns the n largest indices from a numpy array.\"\"\"\n",
    "    flat = ary.flatten()\n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    return np.unravel_index(indices, ary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiAccuracy(outputMap, labelMap, topK=5):\n",
    "    pred = largest_indices(outputMap, topK)\n",
    "    gt = np.unravel_index(labelMap.argmax(), labelMap.shape)\n",
    "    dist_arr = []\n",
    "    for i in range(len(pred[0])):\n",
    "        dist = math.sqrt((pred[0][i] - gt[0]) ** 2 + (pred[1][i] - gt[1]) ** 2)\n",
    "        dist_arr.append(dist)\n",
    "    \n",
    "    min_val = np.min(dist_arr)\n",
    "    min_idx = np.argmin(dist_arr)\n",
    "    within_radius = 0\n",
    "    if min_val <= 4:\n",
    "        within_radius = 1\n",
    "    return 0, min_val, (pred[0][min_idx], pred[1][min_idx]), (gt[0], gt[1]), within_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Cross Validation No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_num = 0 # Change this variable based on the split that you want to test on\n",
    "repo_dir = \"/home/fbd/rrc/submission/INFER-code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the corresponding model for each split\n",
    "checkpoint_path = os.path.join(repo_dir, \"models\", \"kitti-main\", \"cv-0\", \"checkpoint_future.tar\")\n",
    "# checkpoint_path = os.path.join(repo_dir, \"models\", \"kitti-main\", \"cv-1\", \"checkpoint_future.tar\")\n",
    "# checkpoint_path = os.path.join(repo_dir, \"models\", \"kitti-main\", \"cv-2\", \"checkpoint_future.tar\")\n",
    "# checkpoint_path = os.path.join(repo_dir, \"models\", \"kitti-main\", \"cv-3\", \"checkpoint_future.tar\")\n",
    "# checkpoint_path = os.path.join(repo_dir, \"models\", \"kitti-main\", \"cv-4\", \"checkpoint_future.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "model = SkipLSTMEnDe(activation=\"relu\", initType=\"default\", numChannels=5, imageHeight=256, imageWidth=256, batchnorm=False, softmax=False)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model = model.cuda()\n",
    "model.convlstm = model.convlstm.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/fbd/rrc/submission/INFER-datasets/kitti\"\n",
    "val_dir = os.path.join(data_dir, \"final-validation\", \"test\" + str(cv_num) + \".csv\")\n",
    "val_dataset = KittiDataset(data_dir, height=256, width=256, train=False, infoPath=val_dir, augmentation=False, groundTruth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Prediction (Final, Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_512 = torch.nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "labelTransform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "targetGTDir = os.path.join(data_dir, 'targetGT')\n",
    "valLoss1, valLoss2, valLoss3, valLoss4, valLoss, valLoss8 = [], [], [], [], [], []\n",
    "topK = 5\n",
    "totalPreds = 0\n",
    "hitPreds = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbd/anaconda3/envs/torchenv/lib/python3.5/site-packages/torch/nn/functional.py:1749: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeqNum: 1, KittiSeqNum: 8, VehicleNum: 8, numFrames: 61, loss: 3.9876011257024713, len(seqLoss): 40\n",
      "SeqNum: 2, KittiSeqNum: 12, VehicleNum: 1, numFrames: 61, loss: 7.284705841492939, len(seqLoss): 40\n",
      "SeqNum: 3, KittiSeqNum: 20, VehicleNum: 0, numFrames: 61, loss: 1.3524888238242274, len(seqLoss): 40\n",
      "SeqNum: 4, KittiSeqNum: 20, VehicleNum: 4, numFrames: 61, loss: 2.158720549558786, len(seqLoss): 40\n",
      "SeqNum: 5, KittiSeqNum: 20, VehicleNum: 13, numFrames: 61, loss: 15.994484014651112, len(seqLoss): 40\n",
      "SeqNum: 6, KittiSeqNum: 20, VehicleNum: 46, numFrames: 61, loss: 18.530074029798385, len(seqLoss): 40\n",
      "SeqNum: 7, KittiSeqNum: 20, VehicleNum: 122, numFrames: 61, loss: 6.200929585052649, len(seqLoss): 40\n",
      "SeqNum: 8, KittiSeqNum: 20, VehicleNum: 122, numFrames: 61, loss: 3.5518860892469393, len(seqLoss): 40\n",
      "SeqNum: 9, KittiSeqNum: 5, VehicleNum: 31, numFrames: 61, loss: 1.821345406222812, len(seqLoss): 40\n",
      "SeqNum: 10, KittiSeqNum: 18, VehicleNum: 6, numFrames: 61, loss: 5.484102430278062, len(seqLoss): 40\n",
      "SeqNum: 11, KittiSeqNum: 18, VehicleNum: 6, numFrames: 61, loss: 7.529304918116319, len(seqLoss): 40\n",
      "SeqNum: 12, KittiSeqNum: 7, VehicleNum: 22, numFrames: 61, loss: 0.9678694160529716, len(seqLoss): 40\n",
      "SeqNum: 13, KittiSeqNum: 11, VehicleNum: 0, numFrames: 61, loss: 3.0902948941087756, len(seqLoss): 40\n",
      "SeqNum: 14, KittiSeqNum: 11, VehicleNum: 35, numFrames: 61, loss: 4.888660304632978, len(seqLoss): 40\n",
      "SeqNum: 15, KittiSeqNum: 57, VehicleNum: 1, numFrames: 61, loss: 0.0, len(seqLoss): 40\n",
      "SeqNum: 16, KittiSeqNum: 57, VehicleNum: 1, numFrames: 61, loss: 1.875, len(seqLoss): 40\n"
     ]
    }
   ],
   "source": [
    "debug, prevOut, state = True, None, None\n",
    "prevChannels = None\n",
    "xValsGT, yValsGT, xValsPred, yValsPred, xValsPredMulti, yValsPredMulti = [], [], [], [], [], []\n",
    "seqLoss, seqVals = [], []\n",
    "seqNum, seqLen = 0, 0\n",
    "\n",
    "start_time = time.time()\n",
    "model.eval()\n",
    "new_seq_loss = []\n",
    "\n",
    "for i in range(len(val_dataset)):\n",
    "    grid, kittiSeqNum, vehicleId, frame1, frame2, endOfSequence, offset, numFrames, augmentation = val_dataset[i]\n",
    "    \n",
    "    # The Last Channel is the target frame and first n - 1 are source frames\n",
    "    inp = grid[:-1, :].unsqueeze(0).to(device)\n",
    "    currLabel = grid[-1:, :].unsqueeze(0).to(device)\n",
    "    \n",
    "    if numFrames < 60:\n",
    "        continue\n",
    "    \n",
    "    if offset < 20:\n",
    "        prevChannels = inp\n",
    "\n",
    "    if offset >= 20:\n",
    "        new_inp = inp.clone().squeeze(0)\n",
    "        mn, mx = torch.min(prevOut), torch.max(prevOut)\n",
    "        prevOut = (prevOut - mn) / (mx - mn)\n",
    "        new_inp[0] = prevOut\n",
    "        new_inp[4] = prevChannels[0, 4, :, :]        \n",
    "        inp = new_inp.unsqueeze(0).cuda()\n",
    "\n",
    "    # Forward the input and obtain the result\n",
    "    out = model.forward(inp, state)\n",
    "    state = (model.h, model.c, model.h1, model.c1, model.h2, model.c2)\n",
    "    currOutputMap = out.clone()\n",
    "    newOutputMap = upsample_512(currOutputMap)\n",
    "    nextTargetImg = Image.open(os.path.join(targetGTDir, str(kittiSeqNum).zfill(4), \n",
    "                                            str(frame2).zfill(6), str(vehicleId).zfill(6) + '.png'))\n",
    "    \n",
    "    nextTargetTensor = labelTransform(nextTargetImg).unsqueeze(0)\n",
    "    \n",
    "    prevOut = currOutputMap.detach().cpu().squeeze(0).squeeze(0)\n",
    "    currOutputMap = currOutputMap.detach().cpu().numpy().squeeze(0).squeeze(0)\n",
    "    currLabel = currLabel.detach().cpu().numpy().squeeze(0).squeeze(0)\n",
    "    \n",
    "    # Upsampled outputs and inputs\n",
    "    currOutputMap1 = newOutputMap.detach().cpu().numpy().squeeze(0).squeeze(0)\n",
    "    currLabel1 = nextTargetTensor.detach().cpu().numpy().squeeze(0).squeeze(0)\n",
    "    \n",
    "    _, dist1, predCoordinates1, gtCoordinates1 = heatmapAccuracy(currOutputMap1, currLabel1)\n",
    "    _, dist2, predCoordinates2, gtCoordinates2, within_radius = multiAccuracy(currOutputMap1, currLabel1, topK=topK)\n",
    "    \n",
    "    if offset >= 20:\n",
    "        seqLoss.append(dist2)\n",
    "        new_seq_loss.append([dist2])        \n",
    "        totalPreds += 1\n",
    "        if within_radius == 1:\n",
    "            hitPreds += 1\n",
    "\n",
    "    seqLen += 1\n",
    "    xValsGT.append(gtCoordinates1[0])\n",
    "    yValsGT.append(gtCoordinates1[1])\n",
    "    xValsPred.append(predCoordinates1[0])\n",
    "    yValsPred.append(predCoordinates1[1])\n",
    "    xValsPredMulti.append(predCoordinates2[0])\n",
    "    yValsPredMulti.append(predCoordinates2[1])\n",
    "    \n",
    "    if endOfSequence:\n",
    "        seqVals.append(seqLen)\n",
    "        xValsGT, yValsGT, xValsPred, yValsPred, xValsPredMulti, yValsPredMulti = [], [], [], [], [], []\n",
    "        seqNum +=1\n",
    "        state = None\n",
    "        valLoss.append(np.mean(seqLoss))\n",
    "        valLoss8.append(np.mean(seqLoss[:8]))\n",
    "        valLoss1.append(np.mean(seqLoss[:10]))\n",
    "        valLoss2.append(np.mean(seqLoss[:20]))\n",
    "        valLoss3.append(np.mean(seqLoss[:30]))\n",
    "        valLoss4.append(np.mean(seqLoss[:40]))\n",
    "        print(\"SeqNum: {}, KittiSeqNum: {}, VehicleNum: {}, numFrames: {}, loss: {}, len(seqLoss): {}\".format(seqNum, kittiSeqNum, vehicleId, numFrames, np.mean(seqLoss), len(seqLoss)))\n",
    "        seqLoss = []\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1s: 2.209328362278883, 2s: 2.9157824738774303, 3s: 3.683025655408532, 4s: 5.294841714296214\n"
     ]
    }
   ],
   "source": [
    "print(\"1s: {}, 2s: {}, 3s: {}, 4s: {}\".format(np.mean(valLoss1), np.mean(valLoss2), np.mean(valLoss3), np.mean(valLoss4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HitPreds: 455, TotalPreds: 640, Hit Rate: 0.7109375\n"
     ]
    }
   ],
   "source": [
    "print(\"HitPreds: {}, TotalPreds: {}, Hit Rate: {}\".format(hitPreds, totalPreds, hitPreds / totalPreds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
